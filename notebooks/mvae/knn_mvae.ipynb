{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy as cp\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import src.mvae.mt.mvae.utils as utils\n",
    "import torch\n",
    "import yaml\n",
    "\n",
    "from functools import partial\n",
    "from scipy import stats\n",
    "from scipy.io import mmread\n",
    "from sklearn.metrics import f1_score\n",
    "from src.lightning.gene import GeneModule\n",
    "from src.mvae.mt.data import GeneDataset\n",
    "from src.mvae.mt.mvae.components import *\n",
    "from src.mvae.mt.mvae.distributions import *\n",
    "from src.mvae.mt.mvae.models.gene_vae import GeneVAE\n",
    "from src.mvae.mt.mvae.ops.hyperbolics import lorentz_to_poincare\n",
    "from src.mvae.mt.mvae.ops.spherical import spherical_to_projected\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config_path = \"/home/romainlhardy/code/hyperbolic-cancer/configs/lung/lung_e5h5s5.yaml\"\n",
    "with open(config_path, \"r\") as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "dataset = GeneDataset(**config[\"data\"][\"options\"])\n",
    "print(dataset.n_gene)\n",
    "print(dataset.n_batch)\n",
    "print(len(dataset))\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=256, num_workers=16, shuffle=True)\n",
    "\n",
    "x, batch_idx = dataset[np.random.choice(len(dataset))]\n",
    "print(x, batch_idx)\n",
    "print(x.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"/home/romainlhardy/code/hyperbolic-cancer/models/mvae/lung_mvae_e5h5s5.ckpt\"\n",
    "\n",
    "device = \"cuda\"\n",
    "config[\"lightning\"][\"model\"][\"options\"][\"n_gene\"] = dataset.n_gene\n",
    "config[\"lightning\"][\"model\"][\"options\"][\"n_batch\"] = dataset.n_batch\n",
    "module = GeneModule(config).to(device)\n",
    "\n",
    "if checkpoint_path is not None:\n",
    "    module.load_state_dict(torch.load(checkpoint_path)[\"state_dict\"])\n",
    "\n",
    "model = module.model\n",
    "model.eval()\n",
    "\n",
    "x, batch_idx = next(iter(dataloader))\n",
    "outputs = model(x.to(device), batch_idx.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pairwise_distances_euclidean(src: cp.ndarray, dst: cp.ndarray) -> cp.ndarray:\n",
    "    assert src.ndim == 2 and dst.ndim == 2 and src.shape[1] == dst.shape[1]\n",
    "    diff = src[:, None, :] - dst[None, :, :]\n",
    "    return cp.linalg.norm(diff, axis=-1)\n",
    "\n",
    "\n",
    "def pairwise_distances_spherical(src: cp.ndarray, dst: cp.ndarray, radius: float = 1.0) -> cp.ndarray:\n",
    "    assert src.ndim == 2 and dst.ndim == 2 and src.shape[1] == dst.shape[1]\n",
    "    dots = src @ dst.T\n",
    "    cos_theta = cp.clip(dots / (radius ** 2), -1.0, 1.0)\n",
    "    return radius * cp.arccos(cos_theta)\n",
    "\n",
    "\n",
    "def pairwise_distances_hyperboloid(src: cp.ndarray, dst: cp.ndarray, radius: float = 1.0) -> cp.ndarray:\n",
    "    assert src.ndim == 2 and dst.ndim == 2 and src.shape[1] == dst.shape[1]\n",
    "    timelike = cp.outer(src[:, 0], dst[:, 0])\n",
    "    spatial = src[:, 1:] @ dst[:, 1:].T\n",
    "    dots = timelike - spatial\n",
    "    cosh_arg = cp.clip(dots / (radius ** 2), 1.0, None)\n",
    "    return radius * cp.arccosh(cosh_arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_latents(reparametrized, num_components=1):\n",
    "    assert len(reparametrized) > 0\n",
    "\n",
    "    latents = [[] for _ in range(num_components)]\n",
    "    for r in reparametrized:\n",
    "        for i, rr in enumerate(r):\n",
    "            latents[i].append(rr.q_z.loc.detach().cpu().numpy())\n",
    "\n",
    "    for i in range(num_components):\n",
    "        latents[i] = np.concatenate(latents[i], axis=0)\n",
    "        \n",
    "    return latents\n",
    "\n",
    "dataloader = DataLoader(dataset, batch_size=2048, num_workers=16, shuffle=False)\n",
    "\n",
    "reparametrized = []\n",
    "for batch in tqdm(dataloader):\n",
    "    x, batch_idx = batch\n",
    "    with torch.no_grad():\n",
    "        outputs = model(x.to(device), batch_idx.to(device))\n",
    "    reparametrized.append(outputs[\"reparametrized\"])\n",
    "\n",
    "num_components = len(model.components)\n",
    "latents = get_latents(reparametrized, num_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distance_fns(model):\n",
    "    distance_fns = []\n",
    "    for component in model.components:\n",
    "        if isinstance(component, EuclideanComponent):\n",
    "            distance_fns.append(pairwise_distances_euclidean)\n",
    "        elif isinstance(component, SphericalComponent):\n",
    "            distance_fns.append(partial(pairwise_distances_spherical, radius=component.manifold.radius))\n",
    "        elif isinstance(component, HyperbolicComponent):\n",
    "            distance_fns.append(partial(pairwise_distances_hyperboloid, radius=component.manifold.radius))\n",
    "        else:\n",
    "            raise ValueError()\n",
    "    return distance_fns\n",
    "\n",
    "\n",
    "def knn_accuracy(latents, labels, distance_fns, neighbors=15, batch_size=16):\n",
    "    num_samples = len(latents[0])\n",
    "    assert num_samples == len(labels)\n",
    "    assert len(latents) == len(distance_fns)\n",
    "\n",
    "    pred_labels = []\n",
    "    true_labels = []\n",
    "    \n",
    "    pbar = tqdm(range(0, num_samples, batch_size), total=(num_samples + batch_size - 1) // batch_size)\n",
    "    for i in pbar:\n",
    "        j = min(i + batch_size, num_samples)\n",
    "        batch_points = [l[i : j] for l in latents]\n",
    "        batch_labels = labels[i : j]\n",
    "\n",
    "        squared_distances = []\n",
    "        for k, distance_fn in enumerate(distance_fns):\n",
    "            squared_distances.append(distance_fn(cp.asarray(batch_points[k]), cp.asarray(latents[k])) ** 2)\n",
    "        \n",
    "        pairwise_distances = cp.sqrt(sum(squared_distances))\n",
    "        pairwise_distances[cp.arange(j - i), cp.arange(i, j)] = float(\"inf\")\n",
    "        neighbor_indices = cp.argsort(pairwise_distances, axis=-1)[:, :neighbors].get()\n",
    "\n",
    "        neighbor_labels = labels[neighbor_indices]\n",
    "        predicted_labels = stats.mode(neighbor_labels, axis=-1).mode\n",
    "\n",
    "        pred_labels = np.concatenate([pred_labels, predicted_labels])\n",
    "        true_labels = np.concatenate([true_labels, batch_labels])\n",
    "\n",
    "        pbar.set_postfix({\"accuracy\": f\"{(pred_labels == true_labels).mean():.4f}\", \"f1\": f\"{f1_score(true_labels, pred_labels, average='macro', zero_division=0):.4f}\"})\n",
    "\n",
    "    return (pred_labels == true_labels).mean(), f1_score(true_labels, pred_labels, average=\"macro\", zero_division=0)\n",
    "\n",
    "\n",
    "metadata_path = \"/home/romainlhardy/code/hyperbolic-cancer/data/lung/metadata.tsv\"\n",
    "column_name = \"cell_type\"\n",
    "if metadata_path is not None:\n",
    "    labels = pd.read_csv(metadata_path, sep=\"\\t\")[column_name].replace(np.nan, \"Unknown\").values\n",
    "else:\n",
    "    labels = np.ones((len(dataset),)) # Dummy labels\n",
    "    \n",
    "unique_labels = np.unique(labels)\n",
    "label_to_idx = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "labels = np.array([label_to_idx[label] for label in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_accuracy(latents, labels, get_distance_fns(model), neighbors=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_accuracy(latents, labels, get_distance_fns(model), neighbors=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_accuracy(latents, labels, get_distance_fns(model), neighbors=10, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_accuracy(latents, labels, get_distance_fns(model), neighbors=25, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_accuracy(latents, labels, get_distance_fns(model), neighbors=50, batch_size=32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mvae",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
